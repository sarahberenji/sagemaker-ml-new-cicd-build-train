version: 0.2
env:
  shell: /bin/sh
  variables:
    PROCESSING_INSTANCE_TYPE: "ml.m5.xlarge"
    SOURCE_SCRIPT_USE_MODEL_REV: "false"
    APPROVAL_STATUS_MODEL: "Approved"
    APPROVAL_STATUS_PIPELINE: "PendingManualApproval"
    CLOUDWATCH_RULES_UPDATE: "True"
    DATABASE: "ml-test-datasets_rl"
    TABLE: "ml_abalone"
    SNS_MAIN_NAME: "sns-alert-arn"
    SNS_CUSTOM_NAME: "sns-alert-arn" #change to your custom name in case you add an sns topic, e.g. "custom-notification"
  parameter-store:
    CODE_ARTIFACT_DOMAIN: "codeartifact-domain-name"
    DOMAIN_OWNER: "codeartifact-domain-owner"
    CODE_ARTIFACT_REPO: "codeartifact-shared-repo-name"
    TRUSTED_KINESIS_ACCOUNT: "dev-TrustedDefaultKinesisAccount"
phases:
  install:
    runtime-versions:
      python: 3.8
    commands:
      - ENV_TYPE=$(aws ssm get-parameter --name EnvType --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - DATA_BUCKET_ENV=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-data-bucket-name" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - MODEL_BUCKET=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-model-bucket-name" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - EBS_KMS_KEY_ARN=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-kms-ebs-key-arn" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - S3_KMS_KEY_ID=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-kms-s3-key-arn" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - SM_SG=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-sagemaker-sg-ids" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - SM_SUBNETS=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-private-subnet-ids" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - SNS_ARN=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-${SNS_MAIN_NAME}" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - CUSTOM_SNS_ARN=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-${SNS_CUSTOM_NAME}" --query 'Parameter.Value' --output text --region "${AWS_REGION}") # if you introduce a custom sns arn, change this to the name of that, e.g. mlops-${ENV_TYPE}-custom-notification-topic @todo replace with sns arn
      - SAGEMAKER_MODEL_EXECUTION_ROLE_ARN=$(aws ssm get-parameter --name "mlops-${ENV_TYPE}-sm-model-execution-role-arn" --query 'Parameter.Value' --output text --region "${AWS_REGION}")
      - PIPELINE_NAME="${SAGEMAKER_PROJECT_NAME}-inference-pipeline"
      - PIPELINE_DISPLAY_NAME="${SAGEMAKER_PROJECT_NAME}-inference-pipeline"
      - aws codeartifact login --tool pip --domain ${CODE_ARTIFACT_DOMAIN} --domain-owner ${DOMAIN_OWNER} --repository ${CODE_ARTIFACT_REPO}
      - pip install .
      - pip install --disable-pip-version-check -q sagemaker==2.131.0
  pre_build:
    commands:
      - export PYTHONUNBUFFERED=TRUE
      - export SAGEMAKER_PROJECT_NAME_ID="${SAGEMAKER_PROJECT_NAME}-${SAGEMAKER_PROJECT_ID}"
      - #@todo add SOURCE_HEADHASH fetch from model registry metadata
      - . scripts/get-training-metadata.sh "$SAGEMAKER_PROJECT_NAME_ID" "$APPROVAL_STATUS_MODEL"
      - export SOURCE_HEADHASH=${CODEBUILD_RESOLVED_SOURCE_VERSION:0:7}
      - echo "Current revision short headhash is ${SOURCE_HEADHASH}"
      - #@todo change source-scripts-path to fetch from model registry metadata (consider if this should be if else statement in order to either get latest from git or use scripts stored by model training)
      - export SOURCE_PATH="lifecycle/max/${SAGEMAKER_PROJECT_NAME}/${PIPELINE_NAME}/${MODEL_GIT_REVISION}/${SOURCE_HEADHASH}"
      - export SOURCE_SCRIPTS_PATH="s3://${MODEL_BUCKET}/${SOURCE_PATH}/source_scripts"
      - export PIPELINE_PATH="${SOURCE_PATH}/pipeline/inference.json"
      - aws s3 cp ./source_scripts "${SOURCE_SCRIPTS_PATH}/" --recursive
      - mkdir temp
      - echo "Create model package group if it doesnt exist"
      - MODEL_PACKAGE_GROUP_NAME="${SAGEMAKER_PROJECT_NAME}-inference-pipeline"
      - . scripts/create-model-package-group.sh
      - echo "Fetch trigger info"
      - . scripts/fetch-trigger-info.sh
  build:
    commands:
      - . scripts/generate-and-register-inference-pipeline.sh "$MODEL_PACKAGE_GROUP_NAME" "$APPROVAL_STATUS_PIPELINE"
  post_build:
    commands:
      - bash -c "if [ \"$CODEBUILD_BUILD_SUCCEEDING\" == \"0\" ]; then exit 1; fi"
      - echo Build stage successfully completed on `date`
      - echo ">> Create a test run of the inference pipeline registered in model registry"

      - . scripts/get-pipeline-location.sh "$MODEL_PACKAGE_GROUP_NAME" "$APPROVAL_STATUS_PIPELINE"
      - . scripts/create-update-pipeline.sh
      - . scripts/start-pipeline.sh